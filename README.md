
# üõ°Ô∏è Sistema de Monitorizaci√≥n Policial en Tiempo Real (Data Project 2)

Un sistema integral de datos en tiempo real dise√±ado para la monitorizaci√≥n, control y gesti√≥n de alertas por √≥rdenes de alejamiento. Este proyecto combina procesamiento de eventos en *streaming* con sincronizaci√≥n de bases de datos relacionales para ofrecer un panel de control instant√°neo y anal√≠tico a las fuerzas de seguridad.

## üèóÔ∏è Arquitectura del Sistema

![Arquitectura del Sistema](arquitectura/diagrama.svg)

La arquitectura est√° desplegada √≠ntegramente en **Google Cloud Platform (GCP)** y sigue un modelo h√≠brido combinando Streaming y Batch, separando el flujo de telemetr√≠a del flujo transaccional.

### 1. Ingesta y Generaci√≥n de Datos
* **Simulador Python:** Un generador de coordenadas geogr√°ficas simula el movimiento de dispositivos GPS (pulseras de agresores y m√≥viles de v√≠ctimas) usando redes de calles reales mediante `osmnx`.
* **API REST (Cloud Run):** Desarrollada en Flask. Act√∫a como puerta de entrada. Recibe la telemetr√≠a (POST) y expone endpoints CRUD (GET, POST, PUT) para que el Dashboard gestione los perfiles.

### 2.(Streaming de Coordenadas)
* **Pub/Sub:** Act√∫a como bus de mensajer√≠a para desacoplar la ingesta del procesamiento. Separa los t√≥picos de v√≠ctimas y agresores.
* **Dataflow:** Procesa los datos en tiempo real, calcula distancias y manda alertas si se vulnera el per√≠metro de seguridad. Escribe los resultados en **Firestore** (para el mapa en tiempo real) y en **BigQuery** (para procesamiento anal√≠tico).

### 3.(Gesti√≥n Relacional y CDC)
* **Cloud SQL (PostgreSQL):** Base de datos maestra que almacena las entidades (`victimas`, `agresores`, `safe_places`) y sus relaciones. Asegurada mediante IP Privada y *Allowlist* para conexiones externas.
* **Datastream:** Sincroniza la base de datos operativa con el Data Warehouse en tiempo real mediante *Change Data Capture (CDC)* y el m√©todo *Merge*, manteniendo un espejo exacto en BigQuery.

### 4. Transformaci√≥n y Data Warehousing (dbt)
* **BigQuery + dbt:** Modularizaci√≥n del modelado de datos estructurado en tres capas anal√≠ticas:
  * **Staging:** Limpieza inicial de datos crudos (procedentes de Datastream y Dataflow), tratamiento de nulos y *casteo* de tipos (ej. conversi√≥n de coordenadas en *string* a objetos espaciales `GEOGRAPHY` nativos de BigQuery).
  * **Intermediate:** Modelos de cruce y l√≥gica de negocio. Se pre-procesan y unen las entidades relacionales (por ejemplo, consolidando v√≠ctimas, agresores y sus √≥rdenes de alejamiento en una sola vista intermedia) para optimizar el rendimiento de las consultas finales.
  * **Marts:** Capa de consumo final para visualizaci√≥n. Tablas anchas y desnormalizadas donde se enriquece el flujo de *streaming* de alertas con el contexto policial (fotos, nombres completos, lugares seguros recomendados y l√≠mites legales), listas para ser le√≠das por el Dashboard sin latencia ni cruces complejos en tiempo real.

### 5. Visualizaci√≥n y Consumo
* **Streamlit (Cloud Run):** Panel de control interactivo para la polic√≠a.
  * Se conecta v√≠a **Websockets / Firestore** para ver a los actores moverse en el mapa en tiempo real.
  * Llama a la **API** para leer y editar perfiles de la base de datos relacional.
  * Lee directamente desde **Google Cloud Storage (Buckets)** para renderizar de forma segura las fotograf√≠as de v√≠ctimas y agresores.

---

## üõ†Ô∏è Stack Tecnol√≥gico

* **Lenguajes:** Python, SQL
* **GCP Data & Analytics:** BigQuery, Dataflow, Datastream, Pub/Sub, Cloud Storage
* **GCP Compute & Database:** Cloud Run, Cloud SQL (PostgreSQL), Firestore
* **Transformaci√≥n:** dbt (Data Build Tool)
* **Frontend:** Streamlit
* **Infraestructura como C√≥digo (IaC):** Terraform *(Implementado para orquestaci√≥n de recursos)*


---
*Proyecto desarrollado para demostrar capacidades avanzadas en Data Engineering, Streaming Processing y Cloud Architecture.*